{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2d9a3a1-d254-4efc-8658-b280d6df268d",
   "metadata": {},
   "source": [
    "### 2016 - 2020 Presidential Election Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a22b0e6d-3840-46ef-80b3-1359bbf5fff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79de7c01-fd42-48b2-949f-031372827512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_df_overview(df, title):        \n",
    "    print(f\"{title} DF Head:\")\n",
    "    print(df.head())\n",
    "    print(\"----------------------------------\")\n",
    "    print(f\"{title} DF dtypes:\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    for col in df.columns:\n",
    "        print(\"----------------------------------\")\n",
    "        print(f\"{title} DF column value counts:\")\n",
    "\n",
    "        ABRIDGED_ROWS = 16\n",
    "        counts = df[col].value_counts()\n",
    "        if counts.size < 2*ABRIDGED_ROWS:\n",
    "            # Print the counts all together\n",
    "            print(col, \"counts:\")    \n",
    "            print(counts)\n",
    "        else:\n",
    "            # Print top and bottom counts\n",
    "            print(col, \"top counts:\")\n",
    "            print(counts[0:ABRIDGED_ROWS])\n",
    "            print(col, \"bottom counts:\")\n",
    "            print(counts[-ABRIDGED_ROWS:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bfdc18fd-101f-4010-be6d-4182198afde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipping .\\resources\\2016\\2016-precinct-president.csv.zip to .\\resources\\2016\n",
      "Unzipping .\\resources\\2020\\PRESIDENT_precinct_general.csv.zip to .\\resources\\2020\n"
     ]
    }
   ],
   "source": [
    "# The data files are too big to naively manage in git, so they are stored as zip files.\n",
    "def unzip(zip, where):\n",
    "    with ZipFile(zip, 'r') as zObject:   \n",
    "        print(f\"Unzipping {zip} to {where}\")\n",
    "        zObject.extractall(path=where) \n",
    "        \n",
    "path_2016 = os.path.join('.', 'resources', '2016')\n",
    "path_2016_csv = os.path.join('.', 'resources', '2016', '2016-precinct-president.csv')\n",
    "path_2016_zip = os.path.join('.', 'resources', '2016', '2016-precinct-president.csv.zip')\n",
    "path_2020 = os.path.join('.', 'resources', '2020')\n",
    "path_2020_csv = os.path.join('.', 'resources', '2020', 'PRESIDENT_precinct_general.csv')\n",
    "path_2020_zip = os.path.join('.', 'resources', '2020', 'PRESIDENT_precinct_general.csv.zip')\n",
    "\n",
    "unzip(path_2016_zip, path_2016)\n",
    "unzip(path_2020_zip, path_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc17dac-4ee0-4a64-bd25-d0e3c5fd8eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read raw data -- takes several seconds\n",
    "\n",
    "# Encoding wasn't documented but ISO-8859-1 seems to work fine. \n",
    "# Some data types specified here to suppress warnings -- they're actually provided for 2020\n",
    "raw_2016_df = pd.read_csv(path_2016_csv, encoding=\"ISO-8859-1\", \n",
    "                          dtype={\"precinct\":str, \"district\":str, \"party\":str, \"candidate_fec\":str, \"candidate_fec_name\":str, \"votes\":int} )\n",
    "\n",
    "# These come straight from the data documentation:\n",
    "official_2020_dtypes = {'precinct':str,'office':str, 'party_detailed':str, \n",
    "\t\t'party_simplified':str,'mode':str,'votes':int, 'county_name':str,\n",
    "\t\t'county_fips':str, 'jurisdiction_name':str,'jurisdiction_fips':str,\n",
    "\t\t'candidate':str, 'district':str, 'dataverse':str,'year':int,\n",
    "\t\t'stage':str, 'state':str, 'special':str, 'writein':str, 'state_po':str,\n",
    "\t\t'state_fips':str, 'state_cen':str, 'state_ic':str, 'date':str, \n",
    "\t\t'readme_check':str,'magnitude':int}\n",
    "raw_2020_df = pd.read_csv(path_2020_csv, encoding=\"ISO-8859-1\", dtype=official_2020_dtypes )\n",
    "\n",
    "raw_2016_df.shape, raw_2020_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "266d81e6-0644-4d29-a34b-1fc0a2467ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For easier work during development, limit data to the smallest state\n",
    "#raw_2016_df = raw_2016_df.loc[raw_2016_df[\"state\"] == \"Rhode Island\"]\n",
    "#raw_2020_df = raw_2020_df.loc[raw_2020_df[\"state\"] == \"RHODE ISLAND\"]\n",
    "\n",
    "# These don't impact flow or anything like that, just print some info about the DFs to inform cleaning\n",
    "#print_df_overview(raw_2016_df, \"2016 Raw\")\n",
    "#print_df_overview(raw_2020_df, \"2020 Raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1220c5b9-a43a-4d91-a558-514e41a0bcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial:                  (1989234, 37) (1982581, 25)\n",
      "Drop adjustments:         (1988506, 37) (1982207, 25)\n",
      "Drop negative votes:      (1988502, 37) (1974972, 25)\n",
      "Drop extraneous columns:  (1988502, 4) (1974972, 4)\n",
      "2016:\n",
      "Original: 1989234 rows,  140070880 votes\n",
      "Cleaned:  1988502 rows,  140064901 votes -- 99.963% and 99.996%\n",
      "2020:\n",
      "Original: 1982581 rows,  157743486 votes\n",
      "Cleaned:  1974972 rows,  157753369 votes -- 99.616% and 100.006%\n"
     ]
    }
   ],
   "source": [
    "# Get ready to clean up\n",
    "c_2016_df = raw_2016_df.copy()\n",
    "c_2020_df = raw_2020_df.copy()\n",
    "print(\"Initial:                 \", c_2016_df.shape, c_2020_df.shape)\n",
    "\n",
    "# Results include \"statistial adjustments\" which I'm ignoring for the moment\n",
    "c_2016_df = c_2016_df.drop(c_2016_df[c_2016_df.precinct == \"Statistical Adjustments\"].index)\n",
    "c_2020_df = c_2020_df.drop(c_2020_df[c_2020_df.jurisdiction_name == \"{STATISTICAL ADJUSTMENTS}\"].index)\n",
    "print(\"Drop adjustments:        \", c_2016_df.shape, c_2020_df.shape)\n",
    "\n",
    "# Also remove any negative votes -- I don't know what they mean\n",
    "c_2016_df = c_2016_df.drop(c_2016_df[c_2016_df.votes <0].index)\n",
    "c_2020_df = c_2020_df.drop(c_2020_df[c_2020_df.votes <0].index)\n",
    "print(\"Drop negative votes:     \", c_2016_df.shape, c_2020_df.shape)\n",
    "\n",
    "# Narrow down to the interesting columns.\n",
    "#c_2016_df = c_2016_df.loc[:, [\"state\", \"county_name\", \"jurisdiction\", \"candidate\", \"votes\"] ]\n",
    "c_2016_df = c_2016_df.loc[:, [\"state\", \"county_name\", \"candidate\", \"votes\"] ]\n",
    "#c_2020_df = c_2020_df.loc[:, [\"state\", \"county_name\", \"jurisdiction_name\", \"candidate\", \"votes\"] ]\n",
    "c_2020_df = c_2020_df.loc[:, [\"state\", \"county_name\", \"candidate\", \"votes\"] ]\n",
    "print(\"Drop extraneous columns: \", c_2016_df.shape, c_2020_df.shape)\n",
    "\n",
    "# Change a couple column names for consistency and conciseness\n",
    "c_2016_df.rename(columns={\"county_name\": \"county\"}, inplace=True)\n",
    "c_2020_df.rename(columns={\"county_name\": \"county\"}, inplace=True)\n",
    "#c_2020_df.rename(columns={\"jurisdiction_name\": \"jurisdiction\"}, inplace=True)\n",
    "\n",
    "# 2016 uses normal capitalization while 2020 uses all caps\n",
    "# So, California vs CALIFORNIA, and District of Columbia vs DISTRICT OF COLUMBIA\n",
    "# To reconcile them, force everything to lowercase.\n",
    "c_2016_df[\"state\"] = c_2016_df[\"state\"].str.lower()\n",
    "c_2016_df[\"county\"] = c_2016_df[\"county\"].str.lower()\n",
    "#c_2016_df[\"jurisdiction\"] = c_2016_df[\"jurisdiction\"].str.lower()\n",
    "c_2016_df[\"candidate\"] = c_2016_df[\"candidate\"].str.lower()\n",
    "c_2020_df[\"state\"] = c_2020_df[\"state\"].str.lower()\n",
    "c_2020_df[\"county\"] = c_2020_df[\"county\"].str.lower()\n",
    "#c_2020_df[\"jurisdiction\"] = c_2020_df[\"jurisdiction\"].str.lower()\n",
    "c_2020_df[\"candidate\"] = c_2020_df[\"candidate\"].str.lower()\n",
    "\n",
    "# County names actually say \"county\" in the 2016 data, so remove that\n",
    "c_2016_df[\"county\"] = c_2016_df[\"county\"].str.replace(\" county\", \"\")\n",
    "\n",
    "# Reconcile candidate names. Clinton and Biden are equivalent for our purposes, \n",
    "# and Biden and Trump both appear in multiple forms in the datasets.\n",
    "# Any other candidate is just \"other\".\n",
    "dem_names = [\"hillary clinton\", \"biden, joe\", \"joseph biden\", \"joseph r biden\"]\n",
    "rep_names = [\"donald trump\", \"donald j trump\"]\n",
    "combo = dem_names + rep_names\n",
    "c_2016_df.loc[~c_2016_df[\"candidate\"].isin(combo), \"candidate\"] = \"other\"\n",
    "c_2020_df.loc[~c_2020_df[\"candidate\"].isin(combo), \"candidate\"] = \"other\"\n",
    "c_2016_df.loc[c_2016_df[\"candidate\"].isin(dem_names), \"candidate\"] = \"the dem\"\n",
    "c_2016_df.loc[c_2016_df[\"candidate\"].isin(rep_names), \"candidate\"] = \"trump\"\n",
    "c_2020_df.loc[c_2020_df[\"candidate\"].isin(dem_names), \"candidate\"] = \"the dem\"\n",
    "c_2020_df.loc[c_2020_df[\"candidate\"].isin(rep_names), \"candidate\"] = \"trump\"\n",
    "\n",
    "print(\"2016:\")\n",
    "raw_rows = raw_2016_df.shape[0]\n",
    "raw_votes = raw_2016_df['votes'].sum()\n",
    "clean_rows = c_2016_df.shape[0]\n",
    "clean_votes = c_2016_df['votes'].sum()\n",
    "print(f\"Original: {raw_rows:7} rows, {raw_votes:10} votes\")\n",
    "print(f\"Cleaned:  {clean_rows:7} rows, {clean_votes:10} votes -- {clean_rows / raw_rows:.3%} and {clean_votes / raw_votes:.3%}\")\n",
    "\n",
    "print(\"2020:\")\n",
    "raw_rows = raw_2020_df.shape[0]\n",
    "raw_votes = raw_2020_df['votes'].sum()\n",
    "clean_rows = c_2020_df.shape[0]\n",
    "clean_votes = c_2020_df['votes'].sum()\n",
    "print(f\"Original: {raw_rows:7} rows, {raw_votes:10} votes\")\n",
    "print(f\"Cleaned:  {clean_rows:7} rows, {clean_votes:10} votes -- {clean_rows / raw_rows:.3%} and {clean_votes / raw_votes:.3%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3095c450-6d56-42b7-b71a-776005c1bb93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1988502 entries, 0 to 1989233\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Dtype \n",
      "---  ------     ----- \n",
      " 0   state      object\n",
      " 1   county     object\n",
      " 2   candidate  object\n",
      " 3   votes      int64 \n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 395.2 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1974972 entries, 0 to 1982580\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Dtype \n",
      "---  ------     ----- \n",
      " 0   state      object\n",
      " 1   county     object\n",
      " 2   candidate  object\n",
      " 3   votes      int32 \n",
      "dtypes: int32(1), object(3)\n",
      "memory usage: 385.1 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print_df_overview(c_2016_df, \"2016 Cleaned\")\n",
    "#print_df_overview(c_2020_df, \"2020 Cleaned\")\n",
    "c_2016_df.info(memory_usage=\"deep\"), c_2020_df.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "735ad167-dffa-4429-a990-3a2d22a457bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 64.5 GiB for an array with shape (8662095696,) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Combine the dataframes, with each year getting its own column for votes\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# This isn't quite working. I'm pretty sure I need a join, not a merge, but I'm getting sleepy...\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m combo_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc_2016_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_2020_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcounty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcandidate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m print_df_overview(combo_df, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCombo DF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:184\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[0;32m    171\u001b[0m         left_df,\n\u001b[0;32m    172\u001b[0m         right_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m    183\u001b[0m     )\n\u001b[1;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:886\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindicator:\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indicator_pre_merge(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright)\n\u001b[1;32m--> 886\u001b[0m join_index, left_indexer, right_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_join_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    888\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_and_concat(\n\u001b[0;32m    889\u001b[0m     join_index, left_indexer, right_indexer, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    890\u001b[0m )\n\u001b[0;32m    891\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_type)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1151\u001b[0m, in \u001b[0;36m_MergeOperation._get_join_info\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1147\u001b[0m     join_index, right_indexer, left_indexer \u001b[38;5;241m=\u001b[39m _left_join_on_index(\n\u001b[0;32m   1148\u001b[0m         right_ax, left_ax, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1151\u001b[0m     (left_indexer, right_indexer) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_join_indexers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_index:\n\u001b[0;32m   1154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1125\u001b[0m, in \u001b[0;36m_MergeOperation._get_join_indexers\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;66;03m# make mypy happy\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhow \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masof\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_join_indexers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1126\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleft_join_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mright_join_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhow\u001b[49m\n\u001b[0;32m   1127\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1759\u001b[0m, in \u001b[0;36mget_join_indexers\u001b[1;34m(left_keys, right_keys, sort, how)\u001b[0m\n\u001b[0;32m   1757\u001b[0m     _, lidx, ridx \u001b[38;5;241m=\u001b[39m left\u001b[38;5;241m.\u001b[39mjoin(right, how\u001b[38;5;241m=\u001b[39mhow, return_indexers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, sort\u001b[38;5;241m=\u001b[39msort)\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1759\u001b[0m     lidx, ridx \u001b[38;5;241m=\u001b[39m \u001b[43mget_join_indexers_non_unique\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1760\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\n\u001b[0;32m   1761\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lidx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_range_indexer(lidx, \u001b[38;5;28mlen\u001b[39m(left)):\n\u001b[0;32m   1764\u001b[0m     lidx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1799\u001b[0m, in \u001b[0;36mget_join_indexers_non_unique\u001b[1;34m(left, right, sort, how)\u001b[0m\n\u001b[0;32m   1797\u001b[0m     ridx, lidx \u001b[38;5;241m=\u001b[39m libjoin\u001b[38;5;241m.\u001b[39mleft_outer_join(rkey, lkey, count, sort\u001b[38;5;241m=\u001b[39msort)\n\u001b[0;32m   1798\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m how \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1799\u001b[0m     lidx, ridx \u001b[38;5;241m=\u001b[39m \u001b[43mlibjoin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner_join\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1800\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m how \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mouter\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1801\u001b[0m     lidx, ridx \u001b[38;5;241m=\u001b[39m libjoin\u001b[38;5;241m.\u001b[39mfull_outer_join(lkey, rkey, count)\n",
      "File \u001b[1;32mjoin.pyx:47\u001b[0m, in \u001b[0;36mpandas._libs.join.inner_join\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 64.5 GiB for an array with shape (8662095696,) and data type int64"
     ]
    }
   ],
   "source": [
    "# Combine the dataframes, with each year getting its own column for votes\n",
    "# This isn't quite working. I'm pretty sure I need a join, not a merge, but I'm getting sleepy...\n",
    "combo_df = pd.merge(c_2016_df, c_2020_df, on=[\"state\", \"county\", \"candidate\"])\n",
    "print_df_overview(combo_df, \"Combo DF\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
