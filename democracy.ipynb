{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2d9a3a1-d254-4efc-8658-b280d6df268d",
   "metadata": {},
   "source": [
    "### 2016 - 2020 Presidential Election Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a22b0e6d-3840-46ef-80b3-1359bbf5fff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8546b59c-9d3b-4407-b37a-22c6d403e7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpful constants\n",
    "\n",
    "# Party colors\n",
    "COLOR_DEM_BLUE = \"#0055A4\"\n",
    "COLOR_REP_RED = \"#E9141D\"\n",
    "\n",
    "# Cutoff for considering a county \"big\"\n",
    "COUNTY_CARE_COUNT = 100000\n",
    "\n",
    "# According to https://ballotpedia.org/Presidential_battleground_states,_2020\n",
    "# These states were deemed to be competitive in the 2020 election:\n",
    "BATTLEGROUND_STATES = [\"arizona\", \"florida\", \"georgia\", \"iowa\", \"michigan\",\n",
    "                       \"minnesota\", \"nevada\", \"new hampshire\", \"north carolina\", \n",
    "                       \"ohio\", \"pennsylvania\", \"texas\", \"wisconsin\"]\n",
    "\n",
    "# These states went to Trump in 2016, and Biden in 2020:\n",
    "FLIPPED_STATES = [\"pennsylvania\", \"wisconsin\", \"michigan\", \"georgia\", \"arizona\"]\n",
    "\n",
    "# Column names -- mainly for after cleaning when the names are normalized\n",
    "COL_ST = \"state\"\n",
    "COL_CND = \"candidate\"\n",
    "COL_VOTES = \"votes\"\n",
    "COL_CNTY = \"county\"\n",
    "COL_VOTES_16 = \"votes_2016\"\n",
    "COL_VOTES_20 = \"votes_2020\"\n",
    "COL_TOT_16 = \"total_2016\"\n",
    "COL_TOT_20 = \"total_2020\"\n",
    "COL_PCT_16 = \"pct_2016\"\n",
    "COL_PCT_20 = \"pct_2020\"\n",
    "COL_VOTES_CHG = \"votes_change\"\n",
    "COL_PCT_CHG = \"percent_change\"\n",
    "\n",
    "# Candidate names, after normalzing Clinton 2016 and Biden 2020 as \"the major Democratic candidate\",\n",
    "# Trump as \"the major Republican candidate\" in both elections, and everone else as \"other\":\n",
    "CND_OTHER = \"other\"\n",
    "CND_DEM = \"the dem\"\n",
    "CND_REP = \"trump\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79de7c01-fd42-48b2-949f-031372827512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just a function I like using to get an overview of a large data frame:\n",
    "def print_df_overview(df, title):        \n",
    "    print(f\"{title} DF Head:\")\n",
    "    print(df.head())\n",
    "    print(\"----------------------------------\")\n",
    "    print(f\"{title} DF dtypes:\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    for col in df.columns:\n",
    "        print(\"----------------------------------\")\n",
    "        print(f\"{title} DF column value counts:\")\n",
    "\n",
    "        ABRIDGED_ROWS = 16\n",
    "        counts = df[col].value_counts()\n",
    "        if counts.size < 2*ABRIDGED_ROWS:\n",
    "            # Print the counts all together\n",
    "            print(col, \"counts:\")    \n",
    "            print(counts)\n",
    "        else:\n",
    "            # Print top and bottom counts\n",
    "            print(col, \"top counts:\")\n",
    "            print(counts[0:ABRIDGED_ROWS])\n",
    "            print(col, \"bottom counts:\")\n",
    "            print(counts[-ABRIDGED_ROWS:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfdc18fd-101f-4010-be6d-4182198afde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipping .\\resources\\2016\\2016-precinct-president.csv.zip to .\\resources\\2016\n",
      "Unzipping .\\resources\\2020\\PRESIDENT_precinct_general.csv.zip to .\\resources\\2020\n"
     ]
    }
   ],
   "source": [
    "# The data files are too big to naively manage in git, so they are stored as zip files.\n",
    "\n",
    "# Unzip a file to a specified location:\n",
    "def unzip(zip, where):\n",
    "    with ZipFile(zip, 'r') as zObject:   \n",
    "        print(f\"Unzipping {zip} to {where}\")\n",
    "        zObject.extractall(path=where) \n",
    "\n",
    "# Paths for data files, before and after unzipping\n",
    "path_2016 = os.path.join('.', 'resources', '2016')\n",
    "path_2016_csv = os.path.join('.', 'resources', '2016', '2016-precinct-president.csv')\n",
    "path_2016_zip = os.path.join('.', 'resources', '2016', '2016-precinct-president.csv.zip')\n",
    "path_2020 = os.path.join('.', 'resources', '2020')\n",
    "path_2020_csv = os.path.join('.', 'resources', '2020', 'PRESIDENT_precinct_general.csv')\n",
    "path_2020_zip = os.path.join('.', 'resources', '2020', 'PRESIDENT_precinct_general.csv.zip')\n",
    "\n",
    "# Unzip the data files\n",
    "unzip(path_2016_zip, path_2016)\n",
    "unzip(path_2020_zip, path_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bc17dac-4ee0-4a64-bd25-d0e3c5fd8eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1989234, 37), (1982581, 25))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read raw data -- takes several seconds\n",
    "\n",
    "# Encoding wasn't documented for 2016 but ISO-8859-1 seems to work fine. \n",
    "# Some data types are specified here to suppress warnings\n",
    "raw_2016_df = pd.read_csv(path_2016_csv, encoding=\"ISO-8859-1\", \n",
    "                          dtype={\"precinct\":str, \"district\":str, \"party\":str, \"candidate_fec\":str, \"candidate_fec_name\":str, COL_VOTES:int} )\n",
    "\n",
    "# The 2020 data actually includes the encoding and column data types (thanks!):\n",
    "official_2020_dtypes = {'precinct':str,'office':str, 'party_detailed':str, \n",
    "\t\t'party_simplified':str,'mode':str,'votes':int, 'county_name':str,\n",
    "\t\t'county_fips':str, 'jurisdiction_name':str,'jurisdiction_fips':str,\n",
    "\t\t'candidate':str, 'district':str, 'dataverse':str,'year':int,\n",
    "\t\t'stage':str, 'state':str, 'special':str, 'writein':str, 'state_po':str,\n",
    "\t\t'state_fips':str, 'state_cen':str, 'state_ic':str, 'date':str, \n",
    "\t\t'readme_check':str,'magnitude':int}\n",
    "raw_2020_df = pd.read_csv(path_2020_csv, encoding=\"ISO-8859-1\", dtype=official_2020_dtypes )\n",
    "\n",
    "raw_2016_df.shape, raw_2020_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1220c5b9-a43a-4d91-a558-514e41a0bcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial:                  (1989234, 37) (1982581, 25)\n",
      "Drop other offices:       (1954659, 37) (1982581, 25)\n",
      "Drop negative votes:      (1954656, 37) (1975341, 25)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['COL_ST', 'COL_CND', 'COL_VOTES'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDrop negative votes:     \u001b[39m\u001b[38;5;124m\"\u001b[39m, c_2016_df\u001b[38;5;241m.\u001b[39mshape, c_2020_df\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Narrow down to the interesting columns.\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m c_2016_df \u001b[38;5;241m=\u001b[39m \u001b[43mc_2016_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCOL_ST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcounty_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCOL_CND\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCOL_VOTES\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     33\u001b[0m c_2020_df \u001b[38;5;241m=\u001b[39m c_2020_df\u001b[38;5;241m.\u001b[39mloc[:, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCOL_ST\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcounty_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCOL_CND\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCOL_VOTES\u001b[39m\u001b[38;5;124m\"\u001b[39m] ]\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDrop extraneous columns: \u001b[39m\u001b[38;5;124m\"\u001b[39m, c_2016_df\u001b[38;5;241m.\u001b[39mshape, c_2020_df\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hvplot-env\\Lib\\site-packages\\pandas\\core\\indexing.py:1184\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[1;32m-> 1184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1186\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hvplot-env\\Lib\\site-packages\\pandas\\core\\indexing.py:1377\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multi_take_opportunity(tup):\n\u001b[0;32m   1375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multi_take(tup)\n\u001b[1;32m-> 1377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple_same_dim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hvplot-env\\Lib\\site-packages\\pandas\\core\\indexing.py:1020\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_tuple_same_dim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_null_slice(key):\n\u001b[0;32m   1018\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m-> 1020\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mretval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# We should never have retval.ndim < self.ndim, as that should\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;66;03m#  be handled by the _getitem_lowerdim call above.\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m retval\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hvplot-env\\Lib\\site-packages\\pandas\\core\\indexing.py:1420\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1417\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1418\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1422\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[0;32m   1423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hvplot-env\\Lib\\site-packages\\pandas\\core\\indexing.py:1360\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m   1359\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[1;32m-> 1360\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   1362\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1363\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hvplot-env\\Lib\\site-packages\\pandas\\core\\indexing.py:1558\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1555\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[0;32m   1556\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[1;32m-> 1558\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1560\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hvplot-env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hvplot-env\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['COL_ST', 'COL_CND', 'COL_VOTES'] not in index\""
     ]
    }
   ],
   "source": [
    "# Get ready to clean up\n",
    "c_2016_df = raw_2016_df.copy()\n",
    "c_2020_df = raw_2020_df.copy()\n",
    "print(\"Initial:                 \", c_2016_df.shape, c_2020_df.shape)\n",
    "\n",
    "# There are a few areas which notably DON'T require me to do any special handling:\n",
    "# write-in votes, straight-ticket voting, and \"statistical adjustments\"\n",
    "#\n",
    "# Evidently write-in and straight-ticket votes have already been tabulated to the right candidate.\n",
    "# It's odd that some rows don't actually specify a candidate to give the votes to, but if I try to\n",
    "# do anything special for write-in and straight-ticket votes, I get further from the official totals,\n",
    "# not closer. So I believe those rows are redundant with respect to candidates' vote totals.\n",
    "#\n",
    "# I don't know specifically what \"Statistical adjustments\" are or why they need their own rows,\n",
    "# but simply including them consistently brings me closer to the correct totals.\n",
    "\n",
    "# The 2016 data includes votes for a variety of \"offices\" with values such as \"Straight Ticket\",\n",
    "# and \"Unopposed Candidates\". I'm not sure exactly what those mean, but the final count is a lot\n",
    "# closer to the official value without them:\n",
    "c_2016_df = c_2016_df.loc[c_2016_df[\"office\"] == \"US President\"]\n",
    "c_2020_df = c_2020_df.loc[c_2020_df[\"office\"] == \"US PRESIDENT\"]\n",
    "print(\"Drop other offices:      \", c_2016_df.shape, c_2020_df.shape)\n",
    "\n",
    "# For reasons I do not fathom, there are a lot of -1 votes for various candidates,\n",
    "# espescially in New Mexico. I have not been able to find out why, so I'm simply dropping them.\n",
    "# Note some larger negative votes are \"statistical adjustments\" which are retained.\n",
    "c_2016_df = c_2016_df.drop(c_2016_df[c_2016_df.votes == -1].index)\n",
    "c_2020_df = c_2020_df.drop(c_2020_df[c_2020_df.votes == -1].index)\n",
    "print(\"Drop negative votes:     \", c_2016_df.shape, c_2020_df.shape)\n",
    "\n",
    "# Narrow down to the interesting columns.\n",
    "c_2016_df = c_2016_df.loc[:, [COL_ST, \"county_name\", COL_CND, COL_VOTES] ]\n",
    "c_2020_df = c_2020_df.loc[:, [COL_ST, \"county_name\", COL_CND, COL_VOTES] ]\n",
    "print(\"Drop extraneous columns: \", c_2016_df.shape, c_2020_df.shape)\n",
    "\n",
    "# Change a couple column names for consistency and conciseness\n",
    "c_2016_df.rename(columns={\"county_name\": COL_CNTY}, inplace=True)\n",
    "c_2020_df.rename(columns={\"county_name\": COL_CNTY}, inplace=True)\n",
    "\n",
    "# 2016 uses normal capitalization while 2020 uses all caps\n",
    "# So, California vs CALIFORNIA, and District of Columbia vs DISTRICT OF COLUMBIA\n",
    "# To reconcile them, force everything to lowercase.\n",
    "c_2016_df[COL_ST] = c_2016_df[COL_ST].str.lower()\n",
    "c_2016_df[COL_CNTY] = c_2016_df[COL_CNTY].str.lower()\n",
    "c_2016_df[COL_CND] = c_2016_df[COL_CND].str.lower()\n",
    "c_2020_df[COL_ST] = c_2020_df[COL_ST].str.lower()\n",
    "c_2020_df[COL_CNTY] = c_2020_df[COL_CNTY].str.lower()\n",
    "c_2020_df[COL_CND] = c_2020_df[COL_CND].str.lower()\n",
    "\n",
    "# County names actually say \"County\" in the 2016 data, so remove that\n",
    "c_2016_df[COL_CNTY] = c_2016_df[COL_CNTY].str.replace(\" county\", \"\")\n",
    "\n",
    "# Reconcile candidate names. Clinton and Biden are equivalent for our purposes, \n",
    "# and Biden and Trump both appear in multiple forms in the datasets.\n",
    "# Any other candidate is just \"other\".\n",
    "dem_names = [\"hillary clinton\", \"biden, joe\", \"joseph biden\", \"joseph r biden\"]\n",
    "rep_names = [\"donald trump\", \"donald j trump\"]\n",
    "combo = dem_names + rep_names\n",
    "c_2016_df.loc[~c_2016_df[COL_CND].isin(combo), COL_CND] = CND_OTHER\n",
    "c_2020_df.loc[~c_2020_df[COL_CND].isin(combo), COL_CND] = CND_OTHER\n",
    "c_2016_df.loc[c_2016_df[COL_CND].isin(dem_names), COL_CND] = CND_DEM\n",
    "c_2016_df.loc[c_2016_df[COL_CND].isin(rep_names), COL_CND] = CND_REP\n",
    "c_2020_df.loc[c_2020_df[COL_CND].isin(dem_names), COL_CND] = CND_DEM\n",
    "c_2020_df.loc[c_2020_df[COL_CND].isin(rep_names), COL_CND] = CND_REP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb045f5e-b61e-4025-a40b-b0dd9b23862f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out some info to show how much data we lost to cleaning and how it relates to offical results\n",
    "def before_and_after(year, raw_df, clean_df, dem_raw, dem_official_votes, rep_raw, rep_official_votes, all_official_votes):\n",
    "    raw_rows = raw_df.shape[0]\n",
    "    raw_votes = raw_df['votes'].sum()\n",
    "    clean_rows = clean_df.shape[0]\n",
    "    clean_votes = clean_df['votes'].sum()\n",
    "\n",
    "    dem_raw_votes = raw_df.loc[raw_df[COL_CND].str.contains(dem_raw, case=False, na=False)][COL_VOTES].sum()\n",
    "    dem_clean_votes = clean_df.loc[clean_df[COL_CND] == CND_DEM][COL_VOTES].sum()\n",
    "    \n",
    "    rep_raw_votes = raw_df.loc[raw_df[COL_CND].str.contains(rep_raw, case=False, na=False)][COL_VOTES].sum()    \n",
    "    rep_clean_votes = clean_df.loc[clean_df[COL_CND] == CND_REP][COL_VOTES].sum()\n",
    "    \n",
    "    print(f\"{year}:\")\n",
    "    print(f\"Original: {raw_rows:7} rows, {raw_votes:10} votes\")\n",
    "    print(f\"Cleaned:  {clean_rows:7} rows, {clean_votes:10} votes\")\n",
    "    print(f\"Democrat Votes (Wikipedia):   {dem_official_votes:10}\")\n",
    "    print(f\"Democrat Votes (Raw):         {dem_raw_votes:10} ({dem_raw_votes/dem_official_votes:.3%}%)\")\n",
    "    print(f\"Democrat Votes (Clean):       {dem_clean_votes:10} ({dem_clean_votes/dem_official_votes:.3%}%)\")\n",
    "    print(f\"Republican Votes (Wikipedia): {rep_official_votes:10}\")\n",
    "    print(f\"Republican Votes (Raw):       {rep_raw_votes:10} ({rep_raw_votes/rep_official_votes:.3%}%)\")\n",
    "    print(f\"Republican Votes (Clean):     {rep_clean_votes:10} ({rep_clean_votes/rep_official_votes:.3%}%)\")\n",
    "    print(f\"Total Votes (Wikipedia):      {all_official_votes:10}\")\n",
    "    print(f\"Total Votes (Raw):            {raw_votes:10} ({raw_votes/all_official_votes:.3%}%)\")\n",
    "    print(f\"Total Votes (Clean):          {clean_votes:10} ({clean_votes/all_official_votes:.3%}%)\")\n",
    "\n",
    "# Official vote numbers come from the FEC:\n",
    "#\n",
    "# FEDERAL ELECTIONS 2016 Election Results for the U.S. President, the U.S. Senate and the U.S. House of Representatives:\n",
    "# https://www.fec.gov/resources/cms-content/documents/federalelections2016.pdf\n",
    "# FEDERAL ELECTIONS 2020 Election Results for the U.S. President, the U.S. Senate and the U.S. House of Representatives:\n",
    "# https://www.fec.gov/resources/cms-content/documents/federalelections2020.pdf\n",
    "before_and_after(2016, raw_2016_df, c_2016_df, \"hillary clinton\", 65853514, CND_REP, 62984828, 136669276)\n",
    "print()\n",
    "before_and_after(2020, raw_2020_df, c_2020_df, \"biden\", 81283501, CND_REP, 74223975, 158429631)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3095c450-6d56-42b7-b71a-776005c1bb93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Just some debug output for during development\n",
    "#print_df_overview(c_2016_df, \"2016 Cleaned\")\n",
    "#print_df_overview(c_2020_df, \"2020 Cleaned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735ad167-dffa-4429-a990-3a2d22a457bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The two dataframes are so large at this point that merging or joining them is problematic.\n",
    "# I kept running out of memory. So we squash them down a lot first, summing up the votes for\n",
    "# each candidate in each county. Combining all the CND_OTHER rows reduces dataframe size\n",
    "# tremendously, making them much easier to deal with:\n",
    "grouped_2016 = pd.DataFrame(c_2016_df.groupby([COL_ST, COL_CNTY, COL_CND])[COL_VOTES].sum())\n",
    "grouped_2020 = pd.DataFrame(c_2020_df.groupby([COL_ST, COL_CNTY, COL_CND])[COL_VOTES].sum())\n",
    "combo_df = pd.merge(grouped_2016, grouped_2020, on=[COL_ST, COL_CNTY, COL_CND], suffixes=[\"_2016\", \"_2020\"])\n",
    "\n",
    "# The actions above result in a \"multi index\" dataframe, which I don't really want.\n",
    "# So do regular old simple indexing:\n",
    "combo_df.reset_index(inplace=True)\n",
    "\n",
    "print_df_overview(combo_df, \"Combo DF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb95ea45-059e-43ad-9284-9358123a2ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add vote totals columns\n",
    "combo_df[COL_TOT_16] = \"\"\n",
    "combo_df[COL_TOT_20] = \"\"\n",
    "\n",
    "for state in combo_df[COL_ST].unique():\n",
    "    state_slice = combo_df.loc[combo_df[COL_ST] == state]\n",
    "    counties = state_slice[COL_CNTY].unique()\n",
    "    for county in counties:\n",
    "        county_slice = state_slice.loc[combo_df[COL_CNTY] == county]        \n",
    "        total_2016 = county_slice[COL_VOTES_16].sum()\n",
    "        total_2020 = county_slice[COL_VOTES_20].sum()\n",
    "\n",
    "        combo_df.loc[county_slice.index, COL_TOT_16] = total_2016\n",
    "        combo_df.loc[county_slice.index, COL_TOT_20] = total_2020\n",
    "\n",
    "combo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf9a210-30f0-4302-bf12-f19839e76a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the columns showing percentages and changes from 2016-2020\n",
    "combo_df[COL_PCT_16] = combo_df[COL_VOTES_16] / combo_df[COL_TOT_16]\n",
    "combo_df[COL_PCT_20] = combo_df[COL_VOTES_20] / combo_df[COL_TOT_20]\n",
    "combo_df[COL_VOTES_CHG] = combo_df[COL_VOTES_20] - combo_df[COL_VOTES_16]\n",
    "combo_df[COL_PCT_CHG] = combo_df[COL_PCT_20] - combo_df[COL_PCT_16]\n",
    "\n",
    "# Save to CSV to enable some manual sanity checks\n",
    "combo_df.to_csv(\"combined.csv\")\n",
    "\n",
    "# Make the DF for the biggest counties\n",
    "big_counties_df = combo_df.loc[combo_df[COL_TOT_16] >= COUNTY_CARE_COUNT].loc[combo_df[COL_TOT_20] >= COUNTY_CARE_COUNT]\n",
    "\n",
    "# Note many counties we have data for. This doesn't impact any calculation directly, but is nice to know:\n",
    "county_count = len(combo_df[COL_CNTY].unique())\n",
    "big_county_count = len(big_counties_df[COL_CNTY].unique())\n",
    "county_count, big_county_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec53102-58ae-4905-8067-4a2b4efbe7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have a lot of boxplots, and this little function is for adding median values as text\n",
    "# just above the median line in the box:\n",
    "def add_percent_above_value(subplot, x, ylim, value, digits=0, color=\"black\"):\n",
    "    range = ylim[1] - ylim[0]\n",
    "    voffset = range * 0.015\n",
    "    subplot.text(x, value + voffset, f\"{value:.{digits}%}\", va='center', ha='center', color=color, weight='bold')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27020db1-2106-4b0d-a6be-e90c82b838b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function makes a boxplot showing national, all county, and big county percentages\n",
    "# for both election years:\n",
    "def plot_result_comparisons(subplot, candidate_str, title, color):\n",
    "    national_gb = combo_df.groupby(COL_CND).sum()\n",
    "    candidate = candidate_str\n",
    "\n",
    "    national_pct_2016 = national_gb[COL_VOTES_16][candidate_str] / national_gb[COL_VOTES_16].sum()\n",
    "    national_pct_2020 = national_gb[COL_VOTES_20][candidate_str] / national_gb[COL_VOTES_20].sum()\n",
    "\n",
    "    combo_slice = combo_df.loc[combo_df[COL_CND] == candidate_str]\n",
    "    big_slice = big_counties_df.loc[big_counties_df[COL_CND] == candidate_str]\n",
    "\n",
    "    subplot.yaxis.set_major_formatter(mpl.ticker.StrMethodFormatter(\"{x:.0%}\"))\n",
    "\n",
    "    subplot.boxplot(\n",
    "            [national_pct_2016, combo_slice[COL_PCT_16], big_slice[COL_PCT_16],\n",
    "             national_pct_2020, combo_slice[COL_PCT_20], big_slice[COL_PCT_20]],\n",
    "            tick_labels = [\"2016\\nNational\", f\"2016 All\\nCounties\\n({county_count})\", f\"2016 Big\\nCounties\\n({big_county_count})\", \n",
    "                           \"2020\\nNational\", f\"2020 All\\nCounties\\n({county_count})\", f\"2020 Big\\nCounties\\n({big_county_count})\"],\n",
    "            flierprops= {\"alpha\": 0.33} )\n",
    "    subplot.set_title(f\"People Voting for {title}\")\n",
    "    subplot.set_ylabel(f\"Voted for {title} (%)\")\n",
    "    subplot.set_ylim((0,1))\n",
    "    subplot.grid(axis=\"y\", which=\"major\", color=\"lightgrey\")\n",
    "\n",
    "    # Divide the years\n",
    "    subplot.axvline(3.5, color=color, alpha=0.33)\n",
    "    subplot.text(2, 0.98, \"2016\", va=\"center\", ha=\"center\", color=color, weight=\"bold\")\n",
    "    subplot.text(5, 0.98, \"2020\", va=\"center\", ha=\"center\", color=color, weight=\"bold\")\n",
    "\n",
    "    add_percent_above_value(subplot, 1, subplot.get_ylim(), national_pct_2016, color=color)\n",
    "    add_percent_above_value(subplot, 2, subplot.get_ylim(), combo_slice[COL_PCT_16].median(), color=color)\n",
    "    add_percent_above_value(subplot, 3, subplot.get_ylim(), big_slice[COL_PCT_16].median(), color=color)\n",
    "    add_percent_above_value(subplot, 4, subplot.get_ylim(), national_pct_2020, color=color)\n",
    "    add_percent_above_value(subplot, 5, subplot.get_ylim(), combo_slice[COL_PCT_20].median(), color=color)\n",
    "    add_percent_above_value(subplot, 6, subplot.get_ylim(), big_slice[COL_PCT_20].median(), color=color)\n",
    "\n",
    "# Side-by-size boxplots for results for both major candidates:\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1,ncols=2,figsize=(12,6))\n",
    "plot_result_comparisons(ax1, CND_DEM, \"the Democrat\", COLOR_DEM_BLUE)\n",
    "plot_result_comparisons(ax2, CND_REP, \"the Republican\", COLOR_REP_RED)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28e2606-9ae0-47f5-9cc8-0a6082072400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a boxplot for people voting for CND_OTHER candidates, meaning anyone but the two\n",
    "# main party nominees, in 2016 and 2020.\n",
    "combo_slice = combo_df.loc[combo_df[COL_CND] == CND_OTHER]\n",
    "big_slice = big_counties_df.loc[big_counties_df[COL_CND] == CND_OTHER]\n",
    "\n",
    "plt.axes().yaxis.set_major_formatter(mpl.ticker.StrMethodFormatter(\"{x:.0%}\"))\n",
    "plt.boxplot(\n",
    "        [combo_slice[COL_PCT_16], big_slice[COL_PCT_16],\n",
    "         combo_slice[COL_PCT_20], big_slice[COL_PCT_20]],\n",
    "        tick_labels = [\"2016 All\\nCounties\", \"2016 Big\\nCounties\", \n",
    "                       \"2020 All\\nCounties\", \"2020 Big\\nCounties\"],\n",
    "        flierprops= {\"alpha\": 0.33} )\n",
    "plt.title(\"Fewer People Voted for Minor Candidates in 2020\")\n",
    "plt.ylabel(\"Voted For Other (%)\")\n",
    "plt.ylim((0,0.15))\n",
    "plt.grid(axis=\"y\", which=\"major\", color=\"lightgrey\")\n",
    "plt.axvline(2.5, color=\"lightgrey\")\n",
    "\n",
    "add_percent_above_value(plt, 1, plt.ylim(), combo_slice[COL_PCT_16].median(), digits=1)\n",
    "add_percent_above_value(plt, 2, plt.ylim(), big_slice[COL_PCT_16].median(), digits=1)\n",
    "add_percent_above_value(plt, 3, plt.ylim(), combo_slice[COL_PCT_20].median(), digits=1)\n",
    "add_percent_above_value(plt, 4, plt.ylim(), big_slice[COL_PCT_20].median(), digits=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cf8d16-1fac-4467-a29b-b4c9569875d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows=1,ncols=2,figsize=(12,6))\n",
    "\n",
    "ax1.yaxis.set_major_formatter(mpl.ticker.StrMethodFormatter(\"{x:+.0%}\"))\n",
    "ax1.boxplot(\n",
    "        [combo_df.loc[combo_df[COL_CND] == CND_DEM][COL_PCT_CHG], \n",
    "         combo_df.loc[combo_df[COL_CND] == CND_REP][COL_PCT_CHG],\n",
    "         combo_df.loc[combo_df[COL_CND] == CND_OTHER][COL_PCT_CHG]],\n",
    "        tick_labels = [\"Democrat\", \"Republican\", \"Non-Major\"],\n",
    "        showfliers=False )\n",
    "ax1.set_title(\"Across All Counties, Both Candidates Gained Similarly\")\n",
    "ax1.set_ylabel(\"Change in Votes 2016 - 2020\")\n",
    "ax1.set_xlabel(\"---All Counties---\")\n",
    "ax1.set_ylim((-.1,.1))\n",
    "ax1.grid(axis=\"y\", which=\"major\", color=\"lightgrey\")\n",
    "\n",
    "\n",
    "add_percent_above_value(ax1, 1, ax1.get_ylim(), combo_df.loc[combo_df[COL_CND] == CND_DEM][COL_PCT_CHG].median(), digits=1, color=COLOR_DEM_BLUE)\n",
    "add_percent_above_value(ax1, 2, ax1.get_ylim(), combo_df.loc[combo_df[COL_CND] == CND_REP][COL_PCT_CHG].median(), digits=1, color=COLOR_REP_RED)\n",
    "add_percent_above_value(ax1, 3, ax1.get_ylim(), combo_df.loc[combo_df[COL_CND] == CND_OTHER][COL_PCT_CHG].median(), digits=1)\n",
    "\n",
    "ax2.yaxis.set_major_formatter(mpl.ticker.StrMethodFormatter(\"{x:.0%}\"))\n",
    "ax2.boxplot(\n",
    "        [big_counties_df.loc[big_counties_df[COL_CND] == CND_DEM][COL_PCT_CHG], \n",
    "         big_counties_df.loc[big_counties_df[COL_CND] == CND_REP][COL_PCT_CHG],\n",
    "         big_counties_df.loc[big_counties_df[COL_CND] == CND_OTHER][COL_PCT_CHG]],\n",
    "        tick_labels = [\"Democrat\", \"Republican\", \"Non-Major\"],\n",
    "        showfliers=False )\n",
    "ax2.set_title(\"Big Counties Helped the Democrats\")\n",
    "ax2.set_ylabel(\"Change in Votes 2016 - 2020\")\n",
    "ax2.set_xlabel(\"----Big Counties----\")\n",
    "ax2.set_ylim((-.1,.1))\n",
    "ax2.grid(axis=\"y\", which=\"major\", color=\"lightgrey\")\n",
    "\n",
    "add_percent_above_value(ax2, 1, ax2.get_ylim(), big_counties_df.loc[big_counties_df[COL_CND] == CND_DEM][COL_PCT_CHG].median(), digits=1, color=COLOR_DEM_BLUE)\n",
    "add_percent_above_value(ax2, 2, ax2.get_ylim(), big_counties_df.loc[big_counties_df[COL_CND] == CND_REP][COL_PCT_CHG].median(), digits=1, color=COLOR_REP_RED)\n",
    "add_percent_above_value(ax2, 3, ax2.get_ylim(), big_counties_df.loc[big_counties_df[COL_CND] == CND_OTHER][COL_PCT_CHG].median(), digits=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7223205-d14c-4e91-825c-ad1c149b17bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatterplot showing relationship between county size and gain for party\n",
    "def scatter_party(subplot, candidate_str, title, color, trendcolor, log):\n",
    "    slice = combo_df.loc[combo_df[COL_CND] == candidate_str]\n",
    "    x = slice[COL_TOT_20] / 1000\n",
    "    y = slice[COL_PCT_CHG]\n",
    "    subplot.set_title(title)\n",
    "\n",
    "    subplot.yaxis.set_major_formatter(mpl.ticker.StrMethodFormatter(\"{x:+.1%}\"))    \n",
    "    subplot.set_title(title)\n",
    "    subplot.set_ylabel(\"Change in Votes\")\n",
    "    subplot.set_xlabel(\"County Size (2020 Vote Total)\")\n",
    "    subplot.set_ylim((-.5, 0.5))\n",
    "\n",
    "    if log:\n",
    "        subplot.scatter(x, y, color=color, alpha=0.05)\n",
    "        subplot.set_xscale(\"log\")\n",
    "    else:\n",
    "        subplot.scatter(x, y, color=color, alpha=0.33)\n",
    "        subplot.set_xscale(\"linear\") # AKA normal\n",
    "    \n",
    "        z = np.polyfit(list(x), list(y), 1)\n",
    "        p = np.poly1d(z)\n",
    "        subplot.plot(x,p(x),trendcolor)\n",
    "\n",
    "    subplot.xaxis.set_major_formatter(mpl.ticker.StrMethodFormatter(\"{x:.0f} K\"))\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2,ncols=2,figsize=(15,12))\n",
    "scatter_party(ax1, CND_DEM, \"Democratic Candidate\", COLOR_DEM_BLUE, \"black\", False)\n",
    "scatter_party(ax2, CND_REP, \"Republican Candidate\", COLOR_REP_RED, \"black\", False)\n",
    "scatter_party(ax3, CND_DEM, \"Democratic Candidate -- Log Scale\", COLOR_DEM_BLUE, \"black\", True)\n",
    "scatter_party(ax4, CND_REP, \"Republican Candidate -- Log Scale\", COLOR_REP_RED, \"black\", True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a29afe8-b1af-4c67-bc42-32140e5dfa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show shift betwen dem / rep / other votes in battleground states, flipped states, and the whole country\n",
    "\n",
    "battleground_slice = combo_df.loc[combo_df[COL_ST].isin(BATTLEGROUND_STATES)]\n",
    "flipped_slice = combo_df.loc[combo_df[COL_ST].isin(FLIPPED_STATES)]\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(nrows=1,ncols=3,figsize=(18,6))\n",
    "\n",
    "ax1.yaxis.set_major_formatter(mpl.ticker.StrMethodFormatter(\"{x:+.0%}\"))\n",
    "ax1.boxplot(\n",
    "        [battleground_slice.loc[battleground_slice[COL_CND] == CND_DEM][COL_PCT_CHG], \n",
    "         battleground_slice.loc[battleground_slice[COL_CND] == CND_REP][COL_PCT_CHG],\n",
    "         battleground_slice.loc[battleground_slice[COL_CND] == CND_OTHER][COL_PCT_CHG]],\n",
    "        tick_labels = [\"Democrat\", \"Republican\", \"Non-Major\"],\n",
    "        showfliers=False )\n",
    "ax1.set_title(\"Counties in Battleground States\")\n",
    "ax1.set_ylabel(\"Change in Votes 2016 - 2020\")\n",
    "ax1.set_xlabel(\"---Counties in Battleground States---\")\n",
    "ax1.set_ylim((-.1,.1))\n",
    "ax1.grid(axis=\"y\", which=\"major\", color=\"lightgrey\")\n",
    "\n",
    "\n",
    "add_percent_above_value(ax1, 1, ax1.get_ylim(), battleground_slice.loc[battleground_slice[COL_CND] == CND_DEM][COL_PCT_CHG].median(), digits=1, color=COLOR_DEM_BLUE)\n",
    "add_percent_above_value(ax1, 2, ax1.get_ylim(), battleground_slice.loc[battleground_slice[COL_CND] == CND_REP][COL_PCT_CHG].median(), digits=1, color=COLOR_REP_RED)\n",
    "add_percent_above_value(ax1, 3, ax1.get_ylim(), battleground_slice.loc[battleground_slice[COL_CND] == CND_OTHER][COL_PCT_CHG].median(), digits=1)\n",
    "\n",
    "\n",
    "ax2.yaxis.set_major_formatter(mpl.ticker.StrMethodFormatter(\"{x:.0%}\"))\n",
    "ax2.boxplot(\n",
    "        [flipped_slice.loc[flipped_slice[COL_CND] == CND_DEM][COL_PCT_CHG], \n",
    "         flipped_slice.loc[flipped_slice[COL_CND] == CND_REP][COL_PCT_CHG],\n",
    "         flipped_slice.loc[flipped_slice[COL_CND] == CND_OTHER][COL_PCT_CHG]],\n",
    "        tick_labels = [\"Democrat\", \"Republican\", \"Non-Major\"],\n",
    "        showfliers=False )\n",
    "ax2.set_title(\"Counties in Flipped States\")\n",
    "ax2.set_ylabel(\"Change in Votes 2016 - 2020\")\n",
    "ax2.set_xlabel(\"----Counties in Flipped States----\")\n",
    "ax2.set_ylim((-.1,.1))\n",
    "ax2.grid(axis=\"y\", which=\"major\", color=\"lightgrey\")\n",
    "\n",
    "add_percent_above_value(ax2, 1, ax2.get_ylim(), flipped_slice.loc[flipped_slice[COL_CND] == CND_DEM][COL_PCT_CHG].median(), digits=1, color=COLOR_DEM_BLUE)\n",
    "add_percent_above_value(ax2, 2, ax2.get_ylim(),  flipped_slice.loc[flipped_slice[COL_CND] == CND_REP][COL_PCT_CHG].median(), digits=1, color=COLOR_REP_RED)\n",
    "add_percent_above_value(ax2, 3, ax2.get_ylim(), flipped_slice.loc[flipped_slice[COL_CND] == CND_OTHER][COL_PCT_CHG].median(), digits=1)\n",
    "\n",
    "\n",
    "ax3.yaxis.set_major_formatter(mpl.ticker.StrMethodFormatter(\"{x:.0%}\"))\n",
    "ax3.boxplot(\n",
    "        [combo_df.loc[combo_df[COL_CND] == CND_DEM][COL_PCT_CHG], \n",
    "         combo_df.loc[combo_df[COL_CND] == CND_REP][COL_PCT_CHG],\n",
    "         combo_df.loc[combo_df[COL_CND] == CND_OTHER][COL_PCT_CHG]],\n",
    "        tick_labels = [\"Democrat\", \"Republican\", \"Non-Major\"],\n",
    "        showfliers=False )\n",
    "ax3.set_title(\"Counties in All States\")\n",
    "ax3.set_ylabel(\"Change in Votes 2016 - 2020\")\n",
    "ax3.set_xlabel(\"----Counties in All States----\")\n",
    "ax3.set_ylim((-.1,.1))\n",
    "ax3.grid(axis=\"y\", which=\"major\", color=\"lightgrey\")\n",
    "\n",
    "add_percent_above_value(ax3, 1, ax3.get_ylim(), combo_df.loc[combo_df[COL_CND] == CND_DEM][COL_PCT_CHG].median(), digits=1, color=COLOR_DEM_BLUE)\n",
    "add_percent_above_value(ax3, 2, ax3.get_ylim(), combo_df.loc[combo_df[COL_CND] == CND_REP][COL_PCT_CHG].median(), digits=1, color=COLOR_REP_RED)\n",
    "add_percent_above_value(ax3, 3, ax3.get_ylim(), combo_df.loc[combo_df[COL_CND] == CND_OTHER][COL_PCT_CHG].median(), digits=1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
